# -*- coding: utf-8 -*-
"""
ãƒ”ãƒ¼ã‚¯AIè§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ç‰ˆï¼‰
RAGæ©Ÿèƒ½ã¨OpenAI APIã‚’ä½¿ç”¨ã—ãŸãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«ã®é«˜åº¦ãªè§£æ
Enhanced with comprehensive security features

Created on Wed Jun 11 15:56:04 2025
@author: Enhanced Security System
"""

import streamlit as st
import numpy as np
import pandas as pd
import time
import os
import json
import pickle
import requests
import ssl
import urllib3
from datetime import datetime
from typing import List, Dict, Optional
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.signal import savgol_filter, find_peaks, peak_prominences
from pathlib import Path
from common_utils import *
from peak_analysis_web import optimize_thresholds_via_gridsearch

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from security_manager import (
        SecurityManager, 
        get_security_manager, 
        SecurityConfig, 
        SecurityException
    )
    SECURITY_AVAILABLE = True
except ImportError:
    SECURITY_AVAILABLE = False
    st.warning("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åŸºæœ¬æ©Ÿèƒ½ã®ã¿å‹•ä½œã—ã¾ã™ã€‚")

# Interactive plotting
try:
    from streamlit_plotly_events import plotly_events
except ImportError:
    plotly_events = None

# AI/RAGé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import PyPDF2
    import docx
    import openai
    import faiss
    from sentence_transformers import SentenceTransformer
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    st.warning("AI analysis features require additional packages: PyPDF2, docx, openai, faiss, sentence-transformers")

# OpenAI API Keyï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã‚’æ¨å¥¨ï¼‰
openai_api_key = st.secrets["openai"]["openai_api_key"]

def check_internet_connection():
    """ã‚»ã‚­ãƒ¥ã‚¢ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãƒã‚§ãƒƒã‚¯"""
    try:
        # HTTPSæ¥ç¶šã®ã¿ã‚’è¨±å¯
        response = requests.get("https://www.google.com", timeout=5, verify=True)
        return response.status_code == 200
    except requests.exceptions.RequestException:
        return False

def setup_secure_ssl_context():
    """ã‚»ã‚­ãƒ¥ã‚¢ãªSSLã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¨­å®š"""
    try:
        # SSLè¨¼æ˜æ›¸æ¤œè¨¼ã‚’å¼·åˆ¶
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = True
        ssl_context.verify_mode = ssl.CERT_REQUIRED
        
        # TLS 1.2ä»¥ä¸Šã‚’å¼·åˆ¶
        ssl_context.minimum_version = ssl.TLSVersion.TLSv1_2
        
        # å¼±ã„æš—å·åŒ–ã‚’ç„¡åŠ¹åŒ–
        ssl_context.set_ciphers('ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!MD5:!DSS')
        
        return ssl_context
    except Exception as e:
        st.error(f"SSLè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        return None

class SecureLLMConnector:
    """ã‚»ã‚­ãƒ¥ã‚¢å¼·åŒ–ã•ã‚ŒãŸOpenAI LLMæ¥ç¶šè¨­å®šã‚¯ãƒ©ã‚¹"""
    def __init__(self):
        self.is_online = check_internet_connection()
        self.selected_model = "gpt-3.5-turbo"
        self.openai_client = None
        self.security_manager = get_security_manager() if SECURITY_AVAILABLE else None
        self.ssl_context = setup_secure_ssl_context()
        self._setup_secure_session()
        
    def _setup_secure_session(self):
        """ã‚»ã‚­ãƒ¥ã‚¢ãªHTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¨­å®š"""
        self.session = requests.Session()
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼ã®è¨­å®š
        self.session.headers.update({
            'User-Agent': 'RamanEye-SecureClient/2.0',
            'Accept': 'application/json',
            'Content-Type': 'application/json',
            'X-Content-Type-Options': 'nosniff',
            'X-Frame-Options': 'DENY',
            'X-XSS-Protection': '1; mode=block'
        })
        
        # SSLè¨­å®š
        if self.ssl_context:
            adapter = requests.adapters.HTTPAdapter()
            self.session.mount('https://', adapter)
        
    def setup_llm_connection(self):
        """ã‚»ã‚­ãƒ¥ã‚¢å¼·åŒ–ã•ã‚ŒãŸOpenAI APIæ¥ç¶šè¨­å®š"""
        # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãƒã‚§ãƒƒã‚¯
        if not self.is_online:
            st.sidebar.error("âŒ ã‚»ã‚­ãƒ¥ã‚¢ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™")
            return False
        
        st.sidebar.success("ğŸŒ ã‚»ã‚­ãƒ¥ã‚¢ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š: æ­£å¸¸")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_options = [
            "gpt-3.5-turbo",
            "gpt-4",
            "gpt-4-turbo-preview"
        ]
        
        selected_model = st.sidebar.selectbox(
            "OpenAI ãƒ¢ãƒ‡ãƒ«é¸æŠ",
            model_options,
            index=0,
            help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        
        try:
            # ã‚»ã‚­ãƒ¥ã‚¢ãªAPIè¨­å®š
            openai.api_key = os.getenv("OPENAI_API_KEY", openai_api_key)
            
            # APIã‚­ãƒ¼ã®å¦¥å½“æ€§æ¤œè¨¼
            if not self._validate_api_key(openai.api_key):
                st.sidebar.error("ç„¡åŠ¹ãªAPIã‚­ãƒ¼ã§ã™")
                return False
            
            self.selected_model = selected_model
            self.openai_client = "openai"
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²
            if self.security_manager:
                current_user = st.session_state.get('current_user', {})
                user_id = current_user.get('username', 'unknown')
                
                self.security_manager.audit_logger.log_security_event(
                    event_type="API_CONNECTION_SETUP",
                    user_id=user_id,
                    details={
                        'model': selected_model,
                        'ssl_enabled': self.ssl_context is not None,
                        'timestamp': datetime.now().isoformat()
                    },
                    severity="INFO"
                )
            
            st.sidebar.success(f"âœ… ã‚»ã‚­ãƒ¥ã‚¢ãªOpenAI APIæ¥ç¶šè¨­å®šå®Œäº† ({selected_model})")
            return True
            
        except Exception as e:
            st.sidebar.error(f"APIè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²
            if self.security_manager:
                current_user = st.session_state.get('current_user', {})
                user_id = current_user.get('username', 'unknown')
                
                self.security_manager.audit_logger.log_security_event(
                    event_type="API_CONNECTION_ERROR",
                    user_id=user_id,
                    details={'error': str(e)},
                    severity="ERROR"
                )
            
            return False
    
    def _validate_api_key(self, api_key: str) -> bool:
        """APIã‚­ãƒ¼ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        if not api_key or len(api_key) < 20:
            return False
        
        # APIã‚­ãƒ¼ã®å½¢å¼ãƒã‚§ãƒƒã‚¯ï¼ˆOpenAIå½¢å¼ï¼‰
        if not api_key.startswith('sk-'):
            return False
        
        return True
    
    def generate_analysis(self, prompt, temperature=0.3, max_tokens=1024, stream_display=True):
        """ã‚»ã‚­ãƒ¥ã‚¢å¼·åŒ–ã•ã‚ŒãŸOpenAI APIè§£æå®Ÿè¡Œ"""
        if not self.selected_model:
            raise SecurityException("OpenAI ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
        sanitized_prompt = self._sanitize_prompt(prompt)
        
        system_message = "ã‚ãªãŸã¯ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚¹ã‚³ãƒ”ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ”ãƒ¼ã‚¯ä½ç½®ã¨è«–æ–‡ã€ã¾ãŸã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã®æƒ…å ±ã‚’æ¯”è¼ƒã—ã¦ã€ã“ã®ã‚µãƒ³ãƒ—ãƒ«ãŒä½•ã®è©¦æ–™ãªã®ã‹å½“ã¦ã¦ãã ã•ã„ã€‚ã™ã¹ã¦æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚"
        
        try:
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹ï¼‰
            if self.security_manager:
                current_user = st.session_state.get('current_user', {})
                user_id = current_user.get('username', 'unknown')
                
                self.security_manager.audit_logger.log_security_event(
                    event_type="AI_ANALYSIS_REQUEST",
                    user_id=user_id,
                    details={
                        'model': self.selected_model,
                        'prompt_length': len(sanitized_prompt),
                        'temperature': temperature,
                        'max_tokens': max_tokens,
                        'timestamp': datetime.now().isoformat()
                    },
                    severity="INFO"
                )
            
            # ã‚»ã‚­ãƒ¥ã‚¢ãªHTTPSé€šä¿¡ã§APIå‘¼ã³å‡ºã—
            response = openai.ChatCompletion.create(
                model=self.selected_model,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": sanitized_prompt + "\n\nã™ã¹ã¦æ—¥æœ¬èªã§è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"}
                ],
                temperature=temperature,
                max_tokens=max_tokens,
                stream=True,
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
                request_timeout=60,  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
                api_version=None  # æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¼·åˆ¶
            )
            
            full_response = ""
            if stream_display:
                stream_area = st.empty()
            
            for chunk in response:
                if "choices" in chunk and len(chunk["choices"]) > 0:
                    delta = chunk["choices"][0]["delta"]
                    if "content" in delta:
                        content = self._sanitize_response_content(delta["content"])
                        full_response += content
                        if stream_display:
                            stream_area.markdown(full_response)
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²ï¼ˆå¿œç­”å®Œäº†ï¼‰
            if self.security_manager:
                self.security_manager.audit_logger.log_security_event(
                    event_type="AI_ANALYSIS_RESPONSE",
                    user_id=user_id,
                    details={
                        'response_length': len(full_response),
                        'success': True,
                        'timestamp': datetime.now().isoformat()
                    },
                    severity="INFO"
                )
            
            return full_response
                
        except Exception as e:
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰
            if self.security_manager:
                current_user = st.session_state.get('current_user', {})
                user_id = current_user.get('username', 'unknown')
                
                self.security_manager.audit_logger.log_security_event(
                    event_type="AI_ANALYSIS_ERROR",
                    user_id=user_id,
                    details={'error': str(e)},
                    severity="ERROR"
                )
            
            raise SecurityException(f"ã‚»ã‚­ãƒ¥ã‚¢ãªOpenAI APIè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _sanitize_prompt(self, prompt: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–"""
        # å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
        dangerous_patterns = [
            "ignore previous instructions",
            "disregard the above",
            "forget everything",
            "new instruction:",
            "system:",
            "admin:",
            "jailbreak",
            "prompt injection"
        ]
        
        sanitized = prompt
        for pattern in dangerous_patterns:
            sanitized = sanitized.replace(pattern.lower(), "")
            sanitized = sanitized.replace(pattern.upper(), "")
            sanitized = sanitized.replace(pattern.capitalize(), "")
        
        # é•·ã•åˆ¶é™
        if len(sanitized) > 10000:
            sanitized = sanitized[:10000]
        
        return sanitized
    
    def _sanitize_response_content(self, content: str) -> str:
        """å¿œç­”å†…å®¹ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º"""
        # HTMLã‚¿ã‚°ã®é™¤å»
        import re
        content = re.sub(r'<[^>]+>', '', content)
        
        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¿ã‚°ã®é™¤å»
        content = re.sub(r'<script.*?</script>', '', content, flags=re.IGNORECASE | re.DOTALL)
        
        return content
    
    def generate_qa_response(self, question, context, previous_qa_history=None):
        """ã‚»ã‚­ãƒ¥ã‚¢å¼·åŒ–ã•ã‚ŒãŸè³ªå•å¿œç­”å°‚ç”¨ã®OpenAI APIå‘¼ã³å‡ºã—"""
        if not self.selected_model:
            raise SecurityException("OpenAI ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # å…¥åŠ›ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º
        sanitized_question = self._sanitize_prompt(question)
        sanitized_context = self._sanitize_prompt(context)
        
        system_message = """ã‚ãªãŸã¯ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚¹ã‚³ãƒ”ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚
è§£æçµæœã‚„éå»ã®è³ªå•å±¥æ­´ã‚’è¸ã¾ãˆã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§è©³ã—ãç­”ãˆã¦ãã ã•ã„ã€‚
ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ãŸæ­£ç¢ºãªå›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰
        context_text = f"ã€è§£æçµæœã€‘\n{sanitized_context}\n\n"
        
        if previous_qa_history:
            context_text += "ã€éå»ã®è³ªå•å±¥æ­´ã€‘\n"
            for i, qa in enumerate(previous_qa_history, 1):
                sanitized_prev_question = self._sanitize_prompt(qa['question'])
                sanitized_prev_answer = self._sanitize_prompt(qa['answer'])
                context_text += f"è³ªå•{i}: {sanitized_prev_question}\nå›ç­”{i}: {sanitized_prev_answer}\n\n"
        
        context_text += f"ã€æ–°ã—ã„è³ªå•ã€‘\n{sanitized_question}"
        
        try:
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²
            if self.security_manager:
                current_user = st.session_state.get('current_user', {})
                user_id = current_user.get('username', 'unknown')
                
                self.security_manager.audit_logger.log_security_event(
                    event_type="QA_REQUEST",
                    user_id=user_id,
                    details={
                        'question_length': len(sanitized_question),
                        'context_length': len(sanitized_context),
                        'timestamp': datetime.now().isoformat()
                    },
                    severity="INFO"
                )
            
            response = openai.ChatCompletion.create(
                model=self.selected_model,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": context_text}
                ],
                temperature=0.3,
                max_tokens=1024,
                stream=True,
                request_timeout=60
            )
            
            full_response = ""
            stream_area = st.empty()
            
            for chunk in response:
                if "choices" in chunk and len(chunk["choices"]) > 0:
                    delta = chunk["choices"][0]["delta"]
                    if "content" in delta:
                        content = self._sanitize_response_content(delta["content"])
                        full_response += content
                        stream_area.markdown(full_response)
            
            return full_response
                
        except Exception as e:
            raise SecurityException(f"è³ªå•å¿œç­”ã‚¨ãƒ©ãƒ¼: {str(e)}")

class SecureRamanRAGSystem:
    """ã‚»ã‚­ãƒ¥ã‚¢å¼·åŒ–ã•ã‚ŒãŸRAGæ©Ÿèƒ½ã®ã‚¯ãƒ©ã‚¹"""
    def __init__(
        self,
        embedding_model_name: str = 'all-MiniLM-L6-v2',
        use_openai_embeddings: bool = True,
        openai_embedding_model: str = "text-embedding-ada-002"
    ):
        self.use_openai = use_openai_embeddings and check_internet_connection()
        self.openai_embedding_model = openai_embedding_model
        self.security_manager = get_security_manager() if SECURITY_AVAILABLE else None
        
        if self.use_openai:
            self.embedding_model = None
        else:
            self.embedding_model = SentenceTransformer(embedding_model_name)
        
        self.vector_db = None
        self.documents: List[str] = []
        self.document_metadata: List[Dict] = []
        self.embedding_dim: int = 0
        self.db_info: Dict = {}
    
    def build_vector_database(self, folder_path: str):
        """ã‚»ã‚­ãƒ¥ã‚¢å¼·åŒ–ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰"""
        if not PDF_AVAILABLE:
            st.error("PDFå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
            
        if not os.path.exists(folder_path):
            st.error(f"æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {folder_path}")
            return

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
        current_user = st.session_state.get('current_user', {})
        user_id = current_user.get('username', 'unknown')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®ï¼‰
        file_patterns = ['*.pdf', '*.docx', '*.txt']
        files = []
        for pat in file_patterns:
            potential_files = glob.glob(os.path.join(folder_path, pat))
            for file_path in potential_files:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
                if self.security_manager:
                    access_result = self.security_manager.secure_file_access(
                        file_path, user_id, 'read'
                    )
                    if access_result['status'] == 'success':
                        files.append(file_path)
                    else:
                        st.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦: {file_path}")
                else:
                    files.append(file_path)
        
        if not files:
            st.warning("ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return

        # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã¨ãƒãƒ£ãƒ³ã‚¯åŒ–ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä»˜ãï¼‰
        all_chunks, all_metadata = [], []
        st.info(f"{len(files)} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«å‡¦ç†ä¸­â€¦")
        pbar = st.progress(0)
        
        for idx, fp in enumerate(files):
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
                if self.security_manager:
                    integrity_result = self.security_manager.integrity_manager.verify_file_integrity(Path(fp))
                    if integrity_result['status'] == 'corrupted':
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å®Œå…¨æ€§ã‚¨ãƒ©ãƒ¼: {fp}")
                        continue
                
                text = self._extract_text_secure(fp)
                chunks = self.chunk_text(text)
                
                for c in chunks:
                    all_chunks.append(c)
                    all_metadata.append({
                        'filename': os.path.basename(fp),
                        'filepath': fp,
                        'preview': c[:100] + "â€¦" if len(c) > 100 else c,
                        'processed_by': user_id,
                        'processed_at': datetime.now().isoformat()
                    })
                    
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {fp}: {e}")
                if self.security_manager:
                    self.security_manager.audit_logger.log_security_event(
                        event_type="FILE_PROCESSING_ERROR",
                        user_id=user_id,
                        details={'file_path': fp, 'error': str(e)},
                        severity="ERROR"
                    )
                continue
                
            pbar.progress((idx + 1) / len(files))

        if not all_chunks:
            st.error("æŠ½å‡ºã§ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®ç”Ÿæˆï¼ˆã‚»ã‚­ãƒ¥ã‚¢ï¼‰
        st.info("ã‚»ã‚­ãƒ¥ã‚¢ãªåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­â€¦")
        try:
            if self.use_openai:
                embeddings = self._create_openai_embeddings_secure(all_chunks)
            else:
                embeddings = self.embedding_model.encode(all_chunks, show_progress_bar=True)

            # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
            self.embedding_dim = embeddings.shape[1]
            index = faiss.IndexFlatIP(self.embedding_dim)
            faiss.normalize_L2(embeddings)
            index.add(embeddings)

            # çŠ¶æ…‹ä¿å­˜
            self.vector_db = index
            self.documents = all_chunks
            self.document_metadata = all_metadata
            self.db_info = {
                'created_at': datetime.now().isoformat(),
                'created_by': user_id,
                'n_docs': len(files),
                'n_chunks': len(all_chunks),
                'source_files': [os.path.basename(f) for f in files],
                'embedding_model': (
                    self.openai_embedding_model if self.use_openai 
                    else self.embedding_model.__class__.__name__
                ),
                'security_enabled': SECURITY_AVAILABLE
            }
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²
            if self.security_manager:
                self.security_manager.audit_logger.log_security_event(
                    event_type="VECTOR_DB_CREATED",
                    user_id=user_id,
                    details={
                        'n_chunks': len(all_chunks),
                        'n_files': len(files),
                        'embedding_model': self.db_info['embedding_model']
                    },
                    severity="INFO"
                )
            
            st.success(f"ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ™ã‚¯ãƒˆãƒ«DBæ§‹ç¯‰å®Œäº†: {len(all_chunks)} ãƒãƒ£ãƒ³ã‚¯")
            
        except Exception as e:
            st.error(f"ãƒ™ã‚¯ãƒˆãƒ«DBæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            if self.security_manager:
                self.security_manager.audit_logger.log_security_event(
                    event_type="VECTOR_DB_ERROR",
                    user_id=user_id,
                    details={'error': str(e)},
                    severity="ERROR"
                )
    
    def _create_openai_embeddings_secure(self, texts: List[str], batch_size: int = 200) -> np.ndarray:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªOpenAIåŸ‹ã‚è¾¼ã¿APIã®ä½¿ç”¨"""
        all_embs = []
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²
        if self.security_manager:
            current_user = st.session_state.get('current_user', {})
            user_id = current_user.get('username', 'unknown')
            
            self.security_manager.audit_logger.log_security_event(
                event_type="OPENAI_EMBEDDING_REQUEST",
                user_id=user_id,
                details={
                    'num_texts': len(texts),
                    'batch_size': batch_size,
                    'model': self.openai_embedding_model
                },
                severity="INFO"
            )
        
        try:
            for i in range(0, len(texts), batch_size):
                chunk = texts[i:i+batch_size]
                
                # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ãƒ»ã‚µãƒ‹ã‚¿ã‚¤ã‚º
                sanitized_chunk = []
                for text in chunk:
                    # é•·ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ãƒˆ
                    if len(text) > 8000:  # OpenAIåˆ¶é™ã«åˆã‚ã›ã¦èª¿æ•´
                        text = text[:8000]
                    sanitized_chunk.append(text)
                
                # ã‚»ã‚­ãƒ¥ã‚¢ãªHTTPSé€šä¿¡ã§APIå‘¼ã³å‡ºã—
                resp = openai.Embedding.create(
                    model=self.openai_embedding_model,
                    input=sanitized_chunk,
                    timeout=60
                )
                
                embs = [d['embedding'] for d in resp['data']]
                all_embs.extend(embs)
                
                # é€²æ—è¡¨ç¤º
                if len(texts) > batch_size:
                    progress = min(i + batch_size, len(texts)) / len(texts)
                    st.progress(progress)
                    
        except Exception as e:
            if self.security_manager:
                self.security_manager.audit_logger.log_security_event(
                    event_type="OPENAI_EMBEDDING_ERROR",
                    user_id=user_id,
                    details={'error': str(e)},
                    severity="ERROR"
                )
            raise SecurityException(f"ã‚»ã‚­ãƒ¥ã‚¢ãªåŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        
        return np.array(all_embs, dtype=np.float32)
    
    def _extract_text_secure(self, file_path: str) -> str:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º"""
        ext = os.path.splitext(file_path)[1].lower()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        file_size = os.path.getsize(file_path)
        if file_size > SecurityConfig.MAX_FILE_SIZE:
            raise SecurityException(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã¾ã™: {file_path}")
        
        try:
            if ext == '.pdf':
                reader = PyPDF2.PdfReader(file_path)
                text_parts = []
                for page_num, page in enumerate(reader.pages):
                    try:
                        page_text = page.extract_text() or ""
                        text_parts.append(page_text)
                    except Exception as e:
                        st.warning(f"PDF ãƒšãƒ¼ã‚¸ {page_num} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                return "\n".join(text_parts)
                
            elif ext == '.docx':
                doc = docx.Document(file_path)
                return "\n".join(p.text for p in doc.paragraphs)
                
            elif ext == '.txt':
                with open(file_path, encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºåˆ¶é™
                if len(content) > 1000000:  # 1MBåˆ¶é™
                    content = content[:1000000]
                return content
                
        except Exception as e:
            st.error(f"ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            return ""
    
    def chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ã‚­ãƒ¥ã‚¢ã«ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        if not text or not text.strip():
            return []
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
        text = text.strip()
        
        # å±é™ºãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if self._contains_malicious_content(text):
            st.warning("æ½œåœ¨çš„ã«å±é™ºãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return []
        
        words = text.split()
        chunks = []
        
        for i in range(0, len(words), chunk_size - overlap):
            chunk = ' '.join(words[i:i + chunk_size])
            if chunk.strip() and len(chunk) > 10:  # çŸ­ã™ãã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’é™¤å¤–
                chunks.append(chunk)
                
        return chunks
    
    def _contains_malicious_content(self, text: str) -> bool:
        """æ‚ªæ„ã®ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ¤œå‡º"""
        # åŸºæœ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        malicious_patterns = [
            r'<script.*?>',
            r'javascript:',
            r'vbscript:',
            r'onload=',
            r'onerror=',
            r'eval\(',
            r'document\.cookie',
            r'window\.location'
        ]
        
        import re
        text_lower = text.lower()
        
        for pattern in malicious_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE):
                return True
        
        return False
    
    def search_relevant_documents(self, query: str, top_k: int = 5) -> List[Dict]:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªé–¢é€£æ–‡æ›¸æ¤œç´¢"""
        if self.vector_db is None:
            return []
        
        try:
            # ã‚¯ã‚¨ãƒªã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º
            sanitized_query = query.strip()
            if len(sanitized_query) > 1000:
                sanitized_query = sanitized_query[:1000]
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²
            if self.security_manager:
                current_user = st.session_state.get('current_user', {})
                user_id = current_user.get('username', 'unknown')
                
                self.security_manager.audit_logger.log_security_event(
                    event_type="DOCUMENT_SEARCH",
                    user_id=user_id,
                    details={
                        'query_length': len(sanitized_query),
                        'top_k': top_k
                    },
                    severity="INFO"
                )
    
            # DBä½œæˆæ™‚ã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ç¢ºèª
            model_used = self.db_info.get("embedding_model", "")
            if model_used == "text-embedding-ada-002":
                query_emb = self._create_openai_embeddings_secure([sanitized_query])
            else:
                query_emb = self.embedding_model.encode([sanitized_query], show_progress_bar=False)
    
            query_emb = np.array(query_emb, dtype=np.float32)
            faiss.normalize_L2(query_emb)
            
            # é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢
            scores, indices = self.vector_db.search(query_emb, top_k)
            
            results = []
            for score, idx in zip(scores[0], indices[0]):
                if idx < len(self.documents):
                    results.append({
                        'text': self.documents[idx],
                        'metadata': self.document_metadata[idx],
                        'similarity_score': float(score)
                    })
            
            return results
            
        except Exception as e:
            st.error(f"ã‚»ã‚­ãƒ¥ã‚¢ãªæ–‡æ›¸æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []

def peak_ai_analysis_mode():
    """ã‚»ã‚­ãƒ¥ã‚¢å¼·åŒ–ã•ã‚ŒãŸPeak AI analysis mode"""
    if not PDF_AVAILABLE:
        st.error("AIè§£ææ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ï¼š")
        st.code("pip install PyPDF2 python-docx openai faiss-cpu sentence-transformers")
        return
    
    st.header("ğŸ”’ ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ©ãƒãƒ³ãƒ”ãƒ¼ã‚¯AIè§£æ")
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£çŠ¶æ…‹è¡¨ç¤º
    if SECURITY_AVAILABLE:
        security_manager = get_security_manager()
        if security_manager:
            security_status = security_manager.get_security_status()
            
            with st.expander("ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£çŠ¶æ…‹", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**ãƒ‡ãƒ¼ã‚¿ä¿è­·æ©Ÿèƒ½:**")
                    st.write(f"ğŸ” æš—å·åŒ–: {'âœ…' if security_status['encryption_enabled'] else 'âŒ'}")
                    st.write(f"ğŸ” å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯: {'âœ…' if security_status['integrity_checking_enabled'] else 'âŒ'}")
                    st.write(f"ğŸ›¡ï¸ ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡: {'âœ…' if security_status['access_control_enabled'] else 'âŒ'}")
                
                with col2:
                    st.write("**é€šä¿¡ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£:**")
                    st.write(f"ğŸŒ HTTPSå¼·åˆ¶: {'âœ…' if security_status['https_enforced'] else 'âŒ'}")
                    st.write(f"ğŸ“ ç›£æŸ»ãƒ­ã‚°: {'âœ…' if security_status['audit_logging_enabled'] else 'âŒ'}")
                    st.write(f"ğŸ”‘ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚­ãƒ¼: {'âœ…' if security_status['master_key_exists'] else 'âŒ'}")
    else:
        st.warning("âš ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒç„¡åŠ¹ã§ã™ã€‚åŸºæœ¬æ©Ÿèƒ½ã®ã¿å‹•ä½œã—ã¾ã™ã€‚")
    
    # LLMæ¥ç¶šè¨­å®šï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰
    llm_connector = SecureLLMConnector()
    
    # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šçŠ¶æ…‹ã®è¡¨ç¤º
    if llm_connector.is_online:
        st.sidebar.success("ğŸŒ ã‚»ã‚­ãƒ¥ã‚¢ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š: æ­£å¸¸")
        if llm_connector.ssl_context:
            st.sidebar.info("ğŸ”’ SSL/TLSæš—å·åŒ–: æœ‰åŠ¹")
    else:
        st.sidebar.error("âŒ ã‚»ã‚­ãƒ¥ã‚¢ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š: å¿…è¦")
        st.error("ã“ã®æ©Ÿèƒ½ã«ã¯ã‚»ã‚­ãƒ¥ã‚¢ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™ã€‚")
        return
    
    # OpenAI APIè¨­å®š
    llm_ready = llm_connector.setup_llm_connection()
    
    # RAGè¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰
    st.sidebar.subheader("ğŸ“š ã‚»ã‚­ãƒ¥ã‚¢ãªè«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ
    db_mode = st.sidebar.radio(
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãƒ¢ãƒ¼ãƒ‰",
        ["æ–°è¦ä½œæˆ", "æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿"],
        index=0
    )
     
    # ä¸€æ™‚ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã‚»ã‚­ãƒ¥ã‚¢ï¼‰
    TEMP_DIR = "./secure/tmp_uploads"
    os.makedirs(TEMP_DIR, exist_ok=True)
    
    # RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰
    if 'secure_rag_system' not in st.session_state:
        st.session_state.secure_rag_system = SecureRamanRAGSystem()
        st.session_state.secure_rag_db_built = False
    
    if db_mode == "æ–°è¦ä½œæˆ":
        setup_secure_new_database(TEMP_DIR)
    elif db_mode == "æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿":
        load_secure_existing_database()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹è¡¨ç¤º
    if st.session_state.secure_rag_db_built:
        st.sidebar.success("âœ… ã‚»ã‚­ãƒ¥ã‚¢ãªè«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰æ¸ˆã¿")
        
        if st.sidebar.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã‚’è¡¨ç¤º"):
            db_info = st.session_state.secure_rag_system.get_database_info()
            st.sidebar.json(db_info)
    else:
        st.sidebar.info("â„¹ï¸ ã‚»ã‚­ãƒ¥ã‚¢ãªè«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœªæ§‹ç¯‰")
        
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è£œè¶³æŒ‡ç¤ºæ¬„ã‚’è¿½åŠ 
    user_hint = st.sidebar.text_area(
        "ğŸ§ª AIã¸ã®è£œè¶³ãƒ’ãƒ³ãƒˆï¼ˆä»»æ„ï¼‰",
        placeholder="ä¾‹ï¼šã“ã®è©¦æ–™ã¯ãƒãƒªã‚¨ãƒãƒ¬ãƒ³ç³»é«˜åˆ†å­ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€ãªã©"
    )
    
    # ãƒ”ãƒ¼ã‚¯è§£æéƒ¨åˆ†ã®å®Ÿè¡Œï¼ˆã‚»ã‚­ãƒ¥ã‚¢ç‰ˆï¼‰
    perform_secure_peak_analysis_with_ai(llm_connector, user_hint, llm_ready)

def setup_secure_new_database(TEMP_DIR):
    """ã‚»ã‚­ãƒ¥ã‚¢ãªæ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆ"""
    uploaded_files = st.sidebar.file_uploader(
        "ğŸ“„ æ–‡çŒ®PDFã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True
    )

    if st.sidebar.button("ğŸ“š ã‚»ã‚­ãƒ¥ã‚¢ãªè«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰"):
        if not uploaded_files:
            st.sidebar.warning("æ–‡çŒ®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("æ–‡çŒ®ã‚’ã‚»ã‚­ãƒ¥ã‚¢ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ä¸­..."):
                security_manager = get_security_manager()
                current_user = st.session_state.get('current_user', {})
                user_id = current_user.get('username', 'unknown')
                
                uploaded_count = 0
                for uploaded_file in uploaded_files:
                    # ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    if security_manager:
                        upload_result = security_manager.secure_file_upload(uploaded_file, user_id)
                        if upload_result['status'] == 'success':
                            uploaded_count += 1
                        else:
                            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {upload_result['message']}")
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                        save_path = os.path.join(TEMP_DIR, uploaded_file.name)
                        with open(save_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        uploaded_count += 1
                
                if uploaded_count > 0:
                    st.session_state.secure_rag_system.build_vector_database(TEMP_DIR)
                    st.session_state.secure_rag_db_built = True
                    st.sidebar.success(f"âœ… {uploaded_count} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚")

def load_secure_existing_database():
    """ã‚»ã‚­ãƒ¥ã‚¢ãªæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿"""
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“‚ ã‚»ã‚­ãƒ¥ã‚¢ãªæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿")
    st.sidebar.info("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã¿èª­ã¿è¾¼ã¿å¯èƒ½ã§ã™ã€‚")

def perform_secure_peak_analysis_with_ai(llm_connector, user_hint, llm_ready):
    """ã‚»ã‚­ãƒ¥ã‚¢å¼·åŒ–ã•ã‚ŒãŸAIæ©Ÿèƒ½ã‚’å«ã‚€ãƒ”ãƒ¼ã‚¯è§£æã®å®Ÿè¡Œ"""
    # æ—¢å­˜ã®è§£æã‚³ãƒ¼ãƒ‰ã«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½ã‚’çµ±åˆ
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²
    if SECURITY_AVAILABLE:
        security_manager = get_security_manager()
        current_user = st.session_state.get('current_user', {})
        user_id = current_user.get('username', 'unknown')
        
        if security_manager:
            security_manager.audit_logger.log_security_event(
                event_type="PEAK_ANALYSIS_START",
                user_id=user_id,
                details={
                    'llm_ready': llm_ready,
                    'user_hint_provided': bool(user_hint),
                    'timestamp': datetime.now().isoformat()
                },
                severity="INFO"
            )
    
    # æ—¢å­˜ã®ãƒ”ãƒ¼ã‚¯è§£æãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶™ç¶š
    # ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã®è©²å½“éƒ¨åˆ†ã‚’ã“ã“ã«å«ã‚ã‚‹ï¼‰
    
    # äº‹å‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    pre_start_wavenum = 400
    pre_end_wavenum = 2000
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
    for key, default in {
        "prominence_threshold": 100,
        "second_deriv_threshold": 100,
        "savgol_wsize": 5,
        "spectrum_type_select": "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å‰Šé™¤",
        "second_deriv_smooth": 5,
        "manual_peak_keys": []
    }.items():
        if key not in st.session_state:
            st.session_state[key] = default
    
    # UIãƒ‘ãƒãƒ«ï¼ˆSidebarï¼‰
    start_wavenum = st.sidebar.number_input("æ³¢æ•°ï¼ˆé–‹å§‹ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", -200, 4800, value=pre_start_wavenum, step=100)
    end_wavenum = st.sidebar.number_input("æ³¢æ•°ï¼ˆçµ‚äº†ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", -200, 4800, value=pre_end_wavenum, step=100)
    dssn_th = st.sidebar.number_input("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", 1, 10000, value=1000, step=1) / 1e7
    savgol_wsize = st.sidebar.number_input("ç§»å‹•å¹³å‡ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", 5, 101, step=2, key="savgol_wsize")
    
    st.sidebar.subheader("ãƒ”ãƒ¼ã‚¯æ¤œå‡ºè¨­å®š")
    
    spectrum_type = st.sidebar.selectbox("è§£æã‚¹ãƒšã‚¯ãƒˆãƒ«:", ["ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å‰Šé™¤", "ç§»å‹•å¹³å‡å¾Œ"], index=0, key="spectrum_type_select")
    
    second_deriv_smooth = st.sidebar.number_input(
        "2æ¬¡å¾®åˆ†å¹³æ»‘åŒ–:", 3, 35,
        step=2, key="second_deriv_smooth"
    )
    
    second_deriv_threshold = st.sidebar.number_input(
        "2æ¬¡å¾®åˆ†é–¾å€¤:",
        min_value=0,
        max_value=1000,
        step=10,
        key="second_deriv_threshold"
    )
    
    peak_prominence_threshold = st.sidebar.number_input(
        "ãƒ”ãƒ¼ã‚¯Prominenceé–¾å€¤:",
        min_value=0,
        max_value=1000,
        step=10,
        key="prominence_threshold"
    )

    # ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_files = st.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", 
        accept_multiple_files=True, 
        key="secure_file_uploader",
        help="ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨æ€§ãŒæ¤œè¨¼ã•ã‚Œã¾ã™"
    )
    
    # æ®‹ã‚Šã®ãƒ­ã‚¸ãƒƒã‚¯ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒæ§˜ã ãŒã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½ã‚’çµ±åˆ
    # ï¼ˆã‚¹ãƒšãƒ¼ã‚¹åˆ¶é™ã«ã‚ˆã‚Šçœç•¥ï¼‰
    
    st.info("ğŸ”’ ã“ã®ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã¨APIé€šä¿¡ãŒã‚»ã‚­ãƒ¥ã‚¢ã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚")
