# -*- coding: utf-8 -*-
"""
ãƒ”ãƒ¼ã‚¯AIè§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆPDFãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½ä»˜ãï¼‰
RAGæ©Ÿèƒ½ã¨OpenAI APIã‚’ä½¿ç”¨ã—ãŸãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«ã®é«˜åº¦ãªè§£æ
Enhanced with PDF report generation

Created on Wed Jun 11 15:56:04 2025
@author: Enhanced System
"""

import streamlit as st
import numpy as np
import pandas as pd
import time
import os
import json
import pickle
import requests
import ssl
import urllib3
import glob
import base64
import io
from datetime import datetime
from typing import List, Dict, Optional
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
from scipy.signal import savgol_filter, find_peaks, peak_prominences
from pathlib import Path

# PDFç”Ÿæˆé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle, PageBreak
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch, cm
    from reportlab.lib import colors
    from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from PIL import Image as PILImage
    PDF_GENERATION_AVAILABLE = True
    print("PDF generation libraries loaded successfully")
except ImportError as e:
    PDF_GENERATION_AVAILABLE = False
    print(f"PDF generation not available: {e}")
    st.warning("PDFãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ï¼šreportlab, Pillow")

# ä»–ã®æ—¢å­˜ã‚¤ãƒ³ãƒãƒ¼ãƒˆ...
from common_utils import *
from peak_analysis_web import optimize_thresholds_via_gridsearch

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ï¼‰
try:
    from security_manager import (
        SecurityManager, 
        get_security_manager, 
        SecurityConfig, 
        SecurityException
    )
    SECURITY_AVAILABLE = True
except ImportError:
    SECURITY_AVAILABLE = False
    st.warning("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åŸºæœ¬æ©Ÿèƒ½ã®ã¿å‹•ä½œã—ã¾ã™ã€‚")

# Interactive plotting
try:
    from streamlit_plotly_events import plotly_events
except ImportError:
    plotly_events = None

# AI/RAGé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ï¼‰
try:
    import PyPDF2
    import docx
    import openai
    import faiss
    from sentence_transformers import SentenceTransformer
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    st.warning("AI analysis features require additional packages: PyPDF2, docx, openai, faiss, sentence-transformers")

# [æ—¢å­˜ã®ã‚¯ãƒ©ã‚¹ã‚’ã“ã“ã«å«ã‚ã‚‹ - LLMConnector, RamanRAGSystem, RamanSpectrumAnalyzerç­‰]
# ä»¥ä¸‹ã¯æ–°ã—ã„PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹

class RamanPDFReportGenerator:
    """ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æPDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.temp_dir = "./temp_pdf_assets"
        os.makedirs(self.temp_dir, exist_ok=True)
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã‚’è©¦è¡Œ
        self.setup_japanese_font()
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ã®è¨­å®š
        self.setup_styles()
    
    def setup_japanese_font(self):
        """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š"""
        self.japanese_font_available = False
        
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ã‚‹æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¢ã™
            font_paths = [
                # Windows
                "C:/Windows/Fonts/msgothic.ttc",
                "C:/Windows/Fonts/meiryo.ttc", 
                "C:/Windows/Fonts/NotoSansCJK-Regular.ttc",
                # macOS
                "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc",
                "/System/Library/Fonts/NotoSansCJK.ttc",
                # Linux
                "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
                "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc"
            ]
            
            for font_path in font_paths:
                if os.path.exists(font_path):
                    try:
                        pdfmetrics.registerFont(TTFont('JapaneseFont', font_path))
                        self.japanese_font_available = True
                        self.japanese_font_name = 'JapaneseFont'
                        break
                    except:
                        continue
            
            if not self.japanese_font_available:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šHelveticaä½¿ç”¨
                self.japanese_font_name = 'Helvetica'
                st.warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è‹±æ•°å­—ã®ã¿æ­£å¸¸ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                
        except Exception as e:
            self.japanese_font_name = 'Helvetica'
            st.warning(f"ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def setup_styles(self):
        """PDFã‚¹ã‚¿ã‚¤ãƒ«ã®è¨­å®š"""
        self.styles = getSampleStyleSheet()
        
        # ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ«ã®è¿½åŠ 
        self.styles.add(ParagraphStyle(
            name='JapaneseTitle',
            parent=self.styles['Title'],
            fontName=self.japanese_font_name,
            fontSize=18,
            spaceAfter=20,
            alignment=TA_CENTER
        ))
        
        self.styles.add(ParagraphStyle(
            name='JapaneseHeading',
            parent=self.styles['Heading1'],
            fontName=self.japanese_font_name,
            fontSize=14,
            spaceAfter=12,
            textColor=colors.darkblue
        ))
        
        self.styles.add(ParagraphStyle(
            name='JapaneseNormal',
            parent=self.styles['Normal'],
            fontName=self.japanese_font_name,
            fontSize=10,
            spaceAfter=6,
            alignment=TA_JUSTIFY
        ))
        
        self.styles.add(ParagraphStyle(
            name='JapaneseCode',
            parent=self.styles['Code'],
            fontName='Courier',
            fontSize=8,
            textColor=colors.darkgreen
        ))
    
    def plotly_to_image(self, fig, filename, width=800, height=600, format='png'):
        """Plotlyã‚°ãƒ©ãƒ•ã‚’PNGç”»åƒã«å¤‰æ›"""
        try:
            # ç”»åƒã¨ã—ã¦ä¿å­˜
            img_path = os.path.join(self.temp_dir, f"{filename}.{format}")
            
            # Plotlyã®è¨­å®š
            fig.update_layout(
                width=width,
                height=height,
                font=dict(size=10),
                margin=dict(l=50, r=50, t=80, b=50)
            )
            
            # ç”»åƒä¿å­˜ï¼ˆkaleidoä½¿ç”¨ã‚’è©¦è¡Œã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§orchestratorï¼‰
            try:
                pio.write_image(fig, img_path, format=format, width=width, height=height, scale=2)
            except Exception as e:
                st.warning(f"Kaleidoã‚¨ãƒ³ã‚¸ãƒ³ä½¿ç”¨å¤±æ•—ã€‚HTMLã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ: {e}")
                # HTMLã¨ã—ã¦ä¿å­˜ã—ã€å¾Œã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆçš„ã«å‡¦ç†
                html_path = os.path.join(self.temp_dir, f"{filename}.html")
                fig.write_html(html_path)
                # ç°¡æ˜“çš„ãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã‚’ä½œæˆ
                self._create_placeholder_image(img_path, width, height, f"Graph: {filename}")
            
            return img_path
            
        except Exception as e:
            st.error(f"ã‚°ãƒ©ãƒ•ç”»åƒå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã‚’ä½œæˆ
            placeholder_path = os.path.join(self.temp_dir, f"{filename}_placeholder.png")
            self._create_placeholder_image(placeholder_path, width, height, f"Graph Error: {filename}")
            return placeholder_path
    
    def _create_placeholder_image(self, path, width, height, text):
        """ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã‚’ä½œæˆ"""
        try:
            from PIL import Image, ImageDraw, ImageFont
            
            # ç™½èƒŒæ™¯ã®ç”»åƒã‚’ä½œæˆ
            img = PILImage.new('RGB', (width, height), color='white')
            draw = ImageDraw.Draw(img)
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸­å¤®ã«æç”»
            try:
                font = ImageFont.load_default()
            except:
                font = None
            
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            x = (width - text_width) // 2
            y = (height - text_height) // 2
            
            draw.text((x, y), text, fill='black', font=font)
            
            # æ ç·šã‚’æç”»
            draw.rectangle([0, 0, width-1, height-1], outline='gray')
            
            img.save(path)
            
        except Exception as e:
            st.warning(f"ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_comprehensive_pdf_report(
        self, 
        file_key: str,
        peak_data: List[Dict],
        analysis_result: str,
        peak_summary_df: pd.DataFrame,
        plotly_figure: go.Figure,
        relevant_docs: List[Dict] = None,
        user_hint: str = None,
        qa_history: List[Dict] = None
    ) -> bytes:
        """åŒ…æ‹¬çš„ãªPDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        if not PDF_GENERATION_AVAILABLE:
            raise Exception("PDFç”Ÿæˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªä¸Šã«ä½œæˆ
        pdf_buffer = io.BytesIO()
        
        try:
            # SimpleDocTemplateã§PDFä½œæˆ
            doc = SimpleDocTemplate(
                pdf_buffer,
                pagesize=A4,
                rightMargin=2*cm,
                leftMargin=2*cm,
                topMargin=2*cm,
                bottomMargin=2*cm
            )
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            story = []
            
            # 1. ã‚¿ã‚¤ãƒˆãƒ«ãƒšãƒ¼ã‚¸
            story.extend(self._create_title_page(file_key))
            
            # 2. å®Ÿè¡Œã‚µãƒãƒªãƒ¼
            story.extend(self._create_executive_summary(peak_data, analysis_result))
            
            # 3. ã‚°ãƒ©ãƒ•ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            if plotly_figure:
                story.extend(self._create_graph_section(plotly_figure, file_key))
            
            # 4. ãƒ”ãƒ¼ã‚¯è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
            story.extend(self._create_peak_details_section(peak_summary_df, peak_data))
            
            # 5. AIè§£æçµæœ
            story.extend(self._create_ai_analysis_section(analysis_result))
            
            # 6. å‚è€ƒæ–‡çŒ®ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if relevant_docs:
                story.extend(self._create_references_section(relevant_docs))
            
            # 7. è£œè¶³æƒ…å ±
            if user_hint:
                story.extend(self._create_additional_info_section(user_hint))
            
            # 8. Q&Aå±¥æ­´ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if qa_history:
                story.extend(self._create_qa_section(qa_history))
            
            # 9. ä»˜éŒ²ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            story.extend(self._create_appendix_section())
            
            # PDFã‚’æ§‹ç¯‰
            doc.build(story)
            
            # ãƒã‚¤ãƒˆé…åˆ—ã¨ã—ã¦è¿”ã™
            pdf_bytes = pdf_buffer.getvalue()
            pdf_buffer.close()
            
            return pdf_bytes
            
        except Exception as e:
            st.error(f"PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise e
    
    def _create_title_page(self, file_key: str) -> List:
        """ã‚¿ã‚¤ãƒˆãƒ«ãƒšãƒ¼ã‚¸ã‚’ä½œæˆ"""
        content = []
        
        # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
        title = Paragraph(
            "ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æãƒ¬ãƒãƒ¼ãƒˆ",
            self.styles['JapaneseTitle']
        )
        content.append(title)
        content.append(Spacer(1, 0.5*inch))
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        file_info = f"""
        <b>è§£æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«:</b> {file_key}<br/>
        <b>ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ—¥æ™‚:</b> {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}<br/>
        <b>ã‚·ã‚¹ãƒ†ãƒ :</b> RamanEye AI Analysis System<br/>
        <b>ãƒãƒ¼ã‚¸ãƒ§ãƒ³:</b> 2.0 (Enhanced Security Edition)
        """
        
        content.append(Paragraph(file_info, self.styles['JapaneseNormal']))
        content.append(Spacer(1, 0.5*inch))
        
        # å…è²¬äº‹é …
        disclaimer = """
        <b>ã€é‡è¦ã€‘æœ¬ãƒ¬ãƒãƒ¼ãƒˆã«ã¤ã„ã¦</b><br/>
        æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯AIã«ã‚ˆã‚‹è‡ªå‹•è§£æçµæœã‚’å«ã‚“ã§ã„ã¾ã™ã€‚
        çµæœã®è§£é‡ˆãŠã‚ˆã³æ´»ç”¨ã«ã¤ã„ã¦ã¯ã€å°‚é–€å®¶ã«ã‚ˆã‚‹æ¤œè¨¼ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
        æ¸¬å®šæ¡ä»¶ã€ã‚µãƒ³ãƒ—ãƒ«å‰å‡¦ç†ã€è£…ç½®è¼ƒæ­£ç­‰ã®è¦å› ãŒçµæœã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        """
        
        content.append(Paragraph(disclaimer, self.styles['JapaneseNormal']))
        content.append(PageBreak())
        
        return content
    
    def _create_executive_summary(self, peak_data: List[Dict], analysis_result: str) -> List:
        """å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
        content = []
        
        content.append(Paragraph("å®Ÿè¡Œã‚µãƒãƒªãƒ¼", self.styles['JapaneseHeading']))
        
        # ãƒ”ãƒ¼ã‚¯çµ±è¨ˆ
        total_peaks = len(peak_data)
        auto_peaks = len([p for p in peak_data if p.get('type') == 'auto'])
        manual_peaks = len([p for p in peak_data if p.get('type') == 'manual'])
        
        summary_text = f"""
        <b>æ¤œå‡ºãƒ”ãƒ¼ã‚¯ç·æ•°:</b> {total_peaks}<br/>
        <b>è‡ªå‹•æ¤œå‡º:</b> {auto_peaks} ãƒ”ãƒ¼ã‚¯<br/>
        <b>æ‰‹å‹•è¿½åŠ :</b> {manual_peaks} ãƒ”ãƒ¼ã‚¯<br/>
        <br/>
        <b>ä¸»è¦æ¤œå‡ºç¯„å›²:</b> {min([p['wavenumber'] for p in peak_data]):.0f} - {max([p['wavenumber'] for p in peak_data]):.0f} cmâ»Â¹
        """
        
        content.append(Paragraph(summary_text, self.styles['JapaneseNormal']))
        content.append(Spacer(1, 0.3*inch))
        
        # AIè§£æçµæœã®è¦ç´„ï¼ˆæœ€åˆã®200æ–‡å­—ï¼‰
        analysis_summary = analysis_result[:200] + "..." if len(analysis_result) > 200 else analysis_result
        content.append(Paragraph("<b>AIè§£æçµæœè¦ç´„:</b>", self.styles['JapaneseNormal']))
        content.append(Paragraph(analysis_summary, self.styles['JapaneseNormal']))
        content.append(Spacer(1, 0.2*inch))
        
        return content
    
    def _create_graph_section(self, plotly_figure: go.Figure, file_key: str) -> List:
        """ã‚°ãƒ©ãƒ•ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        content = []
        
        content.append(Paragraph("ã‚¹ãƒšã‚¯ãƒˆãƒ«ãŠã‚ˆã³ãƒ”ãƒ¼ã‚¯æ¤œå‡ºçµæœ", self.styles['JapaneseHeading']))
        
        try:
            # Plotlyã‚°ãƒ©ãƒ•ã‚’ç”»åƒã«å¤‰æ›
            img_path = self.plotly_to_image(plotly_figure, f"spectrum_{file_key}", width=1000, height=800)
            
            # ç”»åƒã‚’PDFã«è¿½åŠ 
            if os.path.exists(img_path):
                img = Image(img_path, width=7*inch, height=5.6*inch)
                content.append(img)
                content.append(Spacer(1, 0.2*inch))
            
        except Exception as e:
            error_text = f"ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}"
            content.append(Paragraph(error_text, self.styles['JapaneseNormal']))
        
        # ã‚°ãƒ©ãƒ•ã®èª¬æ˜
        graph_description = """
        ä¸Šå›³ã¯ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«ã¨ãƒ”ãƒ¼ã‚¯æ¤œå‡ºçµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
        èµ¤ã„ç‚¹ã¯æ¤œå‡ºã•ã‚ŒãŸãƒ”ãƒ¼ã‚¯ã€ç·‘ã®æ˜Ÿå°ã¯æ‰‹å‹•ã§è¿½åŠ ã•ã‚ŒãŸãƒ”ãƒ¼ã‚¯ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
        ä¸‹éƒ¨ã®ãƒ—ãƒ­ãƒƒãƒˆã¯2æ¬¡å¾®åˆ†ã‚¹ãƒšã‚¯ãƒˆãƒ«ã¨ãƒ”ãƒ¼ã‚¯ã®Prominenceå€¤ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
        """
        
        content.append(Paragraph(graph_description, self.styles['JapaneseNormal']))
        content.append(Spacer(1, 0.2*inch))
        
        return content
    
    def _create_peak_details_section(self, peak_summary_df: pd.DataFrame, peak_data: List[Dict]) -> List:
        """ãƒ”ãƒ¼ã‚¯è©³ç´°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        content = []
        
        content.append(Paragraph("æ¤œå‡ºãƒ”ãƒ¼ã‚¯è©³ç´°", self.styles['JapaneseHeading']))
        
        # DataFrameã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«å¤‰æ›
        table_data = [peak_summary_df.columns.tolist()]  # ãƒ˜ãƒƒãƒ€ãƒ¼
        for _, row in peak_summary_df.iterrows():
            table_data.append(row.tolist())
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ã®è¨­å®š
        table = Table(table_data, colWidths=[1*inch, 1.5*inch, 1.2*inch, 1.2*inch, 1.5*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), self.japanese_font_name),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('FONTNAME', (0, 1), (-1, -1), self.japanese_font_name),
            ('FONTSIZE', (0, 1), (-1, -1), 9),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        
        content.append(table)
        content.append(Spacer(1, 0.3*inch))
        
        return content
    
    def _create_ai_analysis_section(self, analysis_result: str) -> List:
        """AIè§£æçµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        content = []
        
        content.append(Paragraph("AIè§£æçµæœ", self.styles['JapaneseHeading']))
        
        # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½ã«åˆ†å‰²
        paragraphs = analysis_result.split('\n\n')
        
        for para in paragraphs:
            if para.strip():
                # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®ç°¡å˜ãªå¤‰æ›
                para = para.replace('**', '<b>').replace('**', '</b>')
                para = para.replace('*', '<i>').replace('*', '</i>')
                
                content.append(Paragraph(para.strip(), self.styles['JapaneseNormal']))
                content.append(Spacer(1, 0.1*inch))
        
        return content
    
    def _create_references_section(self, relevant_docs: List[Dict]) -> List:
        """å‚è€ƒæ–‡çŒ®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        content = []
        
        content.append(PageBreak())
        content.append(Paragraph("å‚è€ƒæ–‡çŒ®", self.styles['JapaneseHeading']))
        
        for i, doc in enumerate(relevant_docs, 1):
            filename = doc.get('metadata', {}).get('filename', f'æ–‡çŒ®{i}')
            similarity = doc.get('similarity_score', 0.0)
            preview = doc.get('text', '')[:200] + "..." if len(doc.get('text', '')) > 200 else doc.get('text', '')
            
            ref_text = f"""
            <b>{i}. {filename}</b><br/>
            é¡ä¼¼åº¦: {similarity:.3f}<br/>
            å†…å®¹æŠœç²‹: {preview}<br/>
            """
            
            content.append(Paragraph(ref_text, self.styles['JapaneseNormal']))
            content.append(Spacer(1, 0.2*inch))
        
        return content
    
    def _create_additional_info_section(self, user_hint: str) -> List:
        """è£œè¶³æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        content = []
        
        content.append(Paragraph("è£œè¶³æƒ…å ±", self.styles['JapaneseHeading']))
        content.append(Paragraph(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ãƒ’ãƒ³ãƒˆ: {user_hint}", self.styles['JapaneseNormal']))
        content.append(Spacer(1, 0.2*inch))
        
        return content
    
    def _create_qa_section(self, qa_history: List[Dict]) -> List:
        """Q&Aã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        content = []
        
        content.append(PageBreak())
        content.append(Paragraph("è³ªå•å¿œç­”å±¥æ­´", self.styles['JapaneseHeading']))
        
        for i, qa in enumerate(qa_history, 1):
            qa_text = f"""
            <b>è³ªå•{i}:</b> {qa['question']}<br/>
            <b>å›ç­”{i}:</b> {qa['answer']}<br/>
            <i>æ—¥æ™‚: {qa['timestamp']}</i><br/>
            """
            
            content.append(Paragraph(qa_text, self.styles['JapaneseNormal']))
            content.append(Spacer(1, 0.2*inch))
        
        return content
    
    def _create_appendix_section(self) -> List:
        """ä»˜éŒ²ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        content = []
        
        content.append(PageBreak())
        content.append(Paragraph("ä»˜éŒ²", self.styles['JapaneseHeading']))
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        system_info = f"""
        <b>ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:</b><br/>
        ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}<br/>
        ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼: PDF (ReportLabç”Ÿæˆ)<br/>
        AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³: OpenAI GPT Model<br/>
        ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½: {'æœ‰åŠ¹' if SECURITY_AVAILABLE else 'ç„¡åŠ¹'}<br/>
        """
        
        content.append(Paragraph(system_info, self.styles['JapaneseNormal']))
        
        return content
    
    def cleanup_temp_files(self):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            import shutil
            if os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
        except Exception as e:
            st.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")


# æ—¢å­˜ã®é–¢æ•°ã‚’ä¿®æ­£: perform_ai_analysis
def perform_ai_analysis(file_key, final_peak_data, user_hint, llm_connector, peak_summary_df):
    """AIè§£æã‚’å®Ÿè¡Œï¼ˆPDFæ©Ÿèƒ½ä»˜ãï¼‰"""
    with st.spinner("AIè§£æä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„..."):
        analysis_report = None
        start_time = time.time()

        try:
            analyzer = RamanSpectrumAnalyzer()

            # é–¢é€£æ–‡çŒ®ã‚’æ¤œç´¢
            search_terms = ' '.join([f"{p['wavenumber']:.0f}cm-1" for p in final_peak_data[:5]])
            search_query = f"ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚¹ã‚³ãƒ”ãƒ¼ ãƒ”ãƒ¼ã‚¯ {search_terms}"
            relevant_docs = st.session_state.rag_system.search_relevant_documents(search_query, top_k=5)

            # AIã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            analysis_prompt = analyzer.generate_analysis_prompt(
                peak_data=final_peak_data,
                relevant_docs=relevant_docs,
                user_hint=user_hint
            )
            
            # OpenAI APIã§è§£æã‚’å®Ÿè¡Œ
            st.success("OpenAI APIã®å¿œç­”ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºï¼‰")
            full_response = llm_connector.generate_analysis(analysis_prompt)

            # å‡¦ç†æ™‚é–“ã®è¡¨ç¤º
            elapsed = time.time() - start_time
            st.info(f"è§£æã«ã‹ã‹ã£ãŸæ™‚é–“: {elapsed:.2f} ç§’")

            # è§£æçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            model_info = f"OpenAI ({llm_connector.selected_model})"
            st.session_state[f"{file_key}_ai_analysis"] = {
                'analysis': full_response,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'model': model_info,
                'analysis_context': full_response,
                'peak_data': final_peak_data,
                'peak_summary_df': peak_summary_df,
                'relevant_docs': relevant_docs,
                'user_hint': user_hint
            }

            # ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆæ—¢å­˜ï¼‰
            analysis_report = f"""ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æãƒ¬ãƒãƒ¼ãƒˆ
ãƒ•ã‚¡ã‚¤ãƒ«å: {file_key}
è§£ææ—¥æ™‚: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_info}

=== æ¤œå‡ºãƒ”ãƒ¼ã‚¯æƒ…å ± ===
{peak_summary_df.to_string(index=False)}

=== AIè§£æçµæœ ===
{full_response}

=== å‚ç…§æ–‡çŒ® ===
"""
            for i, doc in enumerate(relevant_docs, 1):
                analysis_report += f"{i}. {doc['metadata']['filename']}ï¼ˆé¡ä¼¼åº¦: {doc['similarity_score']:.3f}ï¼‰\n"

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            st.subheader("ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            col1, col2 = st.columns(2)
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            with col1:
                st.download_button(
                    label="ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=analysis_report,
                    file_name=f"raman_analysis_report_{file_key}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    key=f"download_text_report_{file_key}"
                )
            
            # PDFãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            with col2:
                if PDF_GENERATION_AVAILABLE:
                    if st.button(f"ğŸ“Š PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ", key=f"generate_pdf_{file_key}"):
                        generate_pdf_report(file_key, final_peak_data, full_response, peak_summary_df, relevant_docs, user_hint)
                else:
                    st.info("PDFãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆå¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰")

        except Exception as e:
            st.error(f"AIè§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.info("OpenAI APIã®æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚æœ‰åŠ¹ãªAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


def generate_pdf_report(file_key, final_peak_data, analysis_result, peak_summary_df, relevant_docs, user_hint):
    """PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®å®Ÿè¡Œ"""
    
    try:
        with st.spinner("PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
            # PDFãƒ¬ãƒãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
            pdf_generator = RamanPDFReportGenerator()
            
            # ç¾åœ¨è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹Plotlyã‚°ãƒ©ãƒ•ã‚’å–å¾—
            # æ³¨æ„: å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«æ¸¡ã™å¿…è¦ãŒã‚ã‚Šã¾ã™
            plotly_figure = st.session_state.get(f"{file_key}_plotly_figure", None)
            
            # Q&Aå±¥æ­´ã‚’å–å¾—
            qa_history = st.session_state.get(f"{file_key}_qa_history", [])
            
            # PDFã‚’ç”Ÿæˆ
            pdf_bytes = pdf_generator.generate_comprehensive_pdf_report(
                file_key=file_key,
                peak_data=final_peak_data,
                analysis_result=analysis_result,
                peak_summary_df=peak_summary_df,
                plotly_figure=plotly_figure,
                relevant_docs=relevant_docs,
                user_hint=user_hint,
                qa_history=qa_history
            )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            pdf_generator.cleanup_temp_files()
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
            st.download_button(
                label="ğŸ“Š PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=pdf_bytes,
                file_name=f"raman_comprehensive_report_{file_key}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                mime="application/pdf",
                key=f"download_pdf_report_{file_key}"
            )
            
            st.success("âœ… PDFãƒ¬ãƒãƒ¼ãƒˆãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
            
    except Exception as e:
        st.error(f"PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.info("ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚")


# æ—¢å­˜ã®é–¢æ•°ã«Plotlyã‚°ãƒ©ãƒ•ä¿å­˜æ©Ÿèƒ½ã‚’è¿½åŠ 
def render_interactive_plot(result, file_key, spectrum_type):
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’æç”»ï¼ˆPDFç”¨ã«ä¿å­˜æ©Ÿèƒ½ä»˜ãï¼‰"""
    # [æ—¢å­˜ã®ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆã‚³ãƒ¼ãƒ‰...]
    
    # é™¤å¤–ã‚’åæ˜ ã—ãŸãƒ”ãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    filtered_peaks = [
        i for i in result['detected_peaks']
        if i not in st.session_state[f"{file_key}_excluded_peaks"]
    ]
    filtered_prominences = [
        prom for i, prom in zip(result['detected_peaks'], result['detected_prominences'])
        if i not in st.session_state[f"{file_key}_excluded_peaks"]
    ]

    fig = make_subplots(
        rows=3, cols=1,
        shared_xaxes=True,
        subplot_titles=[
            f'{file_key} - {spectrum_type}',
            f'{file_key} - å¾®åˆ†ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¯”è¼ƒ',
            f'{file_key} - Prominence vs æ³¢æ•°'
        ],
        vertical_spacing=0.07,
        row_heights=[0.4, 0.3, 0.3]
    )

    # [æ—¢å­˜ã®ãƒ—ãƒ­ãƒƒãƒˆæç”»ã‚³ãƒ¼ãƒ‰...]
    # ã‚¹ãƒšã‚¯ãƒˆãƒ«æç”»
    fig.add_trace(
        go.Scatter(
            x=result['wavenum'],
            y=result['spectrum'],
            mode='lines',
            name=spectrum_type,
            line=dict(color='blue', width=1)
        ),
        row=1, col=1
    )

    # æœ‰åŠ¹ãªãƒ”ãƒ¼ã‚¯
    if len(filtered_peaks) > 0:
        fig.add_trace(
            go.Scatter(
                x=result['wavenum'][filtered_peaks],
                y=result['spectrum'][filtered_peaks],
                mode='markers',
                name='æ¤œå‡ºãƒ”ãƒ¼ã‚¯ï¼ˆæœ‰åŠ¹ï¼‰',
                marker=dict(color='red', size=8, symbol='circle')
            ),
            row=1, col=1
        )

    # é™¤å¤–ã•ã‚ŒãŸãƒ”ãƒ¼ã‚¯
    excluded_peaks = list(st.session_state[f"{file_key}_excluded_peaks"])
    if len(excluded_peaks) > 0:
        fig.add_trace(
            go.Scatter(
                x=result['wavenum'][excluded_peaks],
                y=result['spectrum'][excluded_peaks],
                mode='markers',
                name='é™¤å¤–ãƒ”ãƒ¼ã‚¯',
                marker=dict(color='gray', size=8, symbol='x')
            ),
            row=1, col=1
        )

    # æ‰‹å‹•ãƒ”ãƒ¼ã‚¯
    for x, y in st.session_state[f"{file_key}_manual_peaks"]:
        fig.add_trace(
            go.Scatter(
                x=[x],
                y=[y],
                mode='markers+text',
                marker=dict(color='green', size=10, symbol='star'),
                text=["æ‰‹å‹•"],
                textposition='top center',
                name="æ‰‹å‹•ãƒ”ãƒ¼ã‚¯",
                showlegend=False
            ),
            row=1, col=1
        )

    # 2æ¬¡å¾®åˆ†
    fig.add_trace(
        go.Scatter(
            x=result['wavenum'],
            y=result['second_derivative'],
            mode='lines',
            name='2æ¬¡å¾®åˆ†',
            line=dict(color='purple', width=1)
        ),
        row=2, col=1
    )

    fig.add_hline(y=0, line_dash="dash", line_color="black", opacity=0.5, row=2, col=1)

    # Prominenceãƒ—ãƒ­ãƒƒãƒˆ
    fig.add_trace(
        go.Scatter(
            x=result['wavenum'][result['all_peaks']],
            y=result['all_prominences'],
            mode='markers',
            name='å…¨ãƒ”ãƒ¼ã‚¯ã®Prominence',
            marker=dict(color='orange', size=4)
        ),
        row=3, col=1
    )
    if len(filtered_peaks) > 0:
        fig.add_trace(
            go.Scatter(
                x=result['wavenum'][filtered_peaks],
                y=filtered_prominences,
                mode='markers',
                name='æœ‰åŠ¹ãªProminence',
                marker=dict(color='red', size=7, symbol='circle')
            ),
            row=3, col=1
        )

    fig.update_layout(height=800, margin=dict(t=80, b=40))
    fig.update_xaxes(title_text="æ³¢æ•° (cmâ»Â¹)", row=3, col=1)
    fig.update_yaxes(title_text="å¼·åº¦", row=1, col=1)
    fig.update_yaxes(title_text="å¾®åˆ†å€¤", row=2, col=1)
    
    # PDFãƒ¬ãƒãƒ¼ãƒˆç”¨ã«Plotlyã‚°ãƒ©ãƒ•ã‚’ä¿å­˜
    st.session_state[f"{file_key}_plotly_figure"] = fig
    
    # [æ—¢å­˜ã®ã‚¯ãƒªãƒƒã‚¯å‡¦ç†ã‚³ãƒ¼ãƒ‰...]
    if plotly_events:
        # [æ—¢å­˜ã®ã‚¯ãƒªãƒƒã‚¯å‡¦ç†ã‚³ãƒ¼ãƒ‰...]
        pass
    else:
        st.plotly_chart(fig, use_container_width=True)


# æ—¢å­˜ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ã«å¤‰æ›´ãªã—ï¼ˆpeak_ai_analysis_modeç­‰ï¼‰
